{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExploreTopic.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDyiKw_yVKzY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "1fcfacae-61e4-4cbb-9f6c-f13f6efe6365"
      },
      "source": [
        "# setup\n",
        "import sys\n",
        "import subprocess\n",
        "import pkg_resources\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "\n",
        "required = {'spacy', 'scikit-learn', 'numpy', \n",
        "            'pandas', 'torch', 'matplotlib', 'wordcloud'}\n",
        "\n",
        "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
        "missing = required - installed\n",
        "\n",
        "if missing:\n",
        "    python = sys.executable\n",
        "    subprocess.check_call([python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pickle\n",
        "from spacy.lang.en import English\n",
        "!python -m spacy download en_core_web_md\n",
        "import en_core_web_md\n",
        "en = English()\n",
        "nlp = en_core_web_md.load()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_md==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4MB)\n",
            "\u001b[K     |████████████████████████████████| 96.4MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.7.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (49.2.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.2.5-cp36-none-any.whl size=98051305 sha256=d653e77c6a71984164b9ed3ef0ad7a3aba375fe80a0e97d52d222a1ec41c5735\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-y6dkf_v9/wheels/df/94/ad/f5cf59224cea6b5686ac4fd1ad19c8a07bc026e13c36502d81\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTtgHsKFeO9Y",
        "colab_type": "text"
      },
      "source": [
        "Trying to explore what the tweets are about"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06PfVegYVjER",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "outputId": "090e3dc4-9d0c-4912-b70f-8952c36dc12a"
      },
      "source": [
        "with open('clean_tweets_10k.pkl', 'rb') as f:\n",
        "    df_tweet = pickle.load(f)\n",
        "print(df_tweet.head())\n",
        "df_tweet.info()\n",
        "print(len(df_tweet))\n",
        "##clean out any rows with null values\n",
        "\n",
        "df_tweet.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Target                                               text\n",
            "0       4  @gypsy_sunday :O omg oh yes, I always forget a...\n",
            "1       4  at least i know @sarahtondryk and family will ...\n",
            "2       0      Yesterday it was sunny and today its raining \n",
            "3       4  Going to see Chelsea Art College today.. shoul...\n",
            "4       0  woken up 'early' 3days in a row and im exhaust...\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Target  10000 non-null  int64 \n",
            " 1   text    10000 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 156.4+ KB\n",
            "10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.994400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.000092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Target\n",
              "count  10000.000000\n",
              "mean       1.994400\n",
              "std        2.000092\n",
              "min        0.000000\n",
              "25%        0.000000\n",
              "50%        0.000000\n",
              "75%        4.000000\n",
              "max        4.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSWyUGZRVsWf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "80063e3a-85f3-48ba-bc34-8fbc8a85098d"
      },
      "source": [
        "#remove punctuation and URLs, and stopwords\n",
        "def tokenize(text, model=nlp, nostopwds=True,  lemma=False):\n",
        "   \n",
        "    tokenlist = []\n",
        "    doc = model(text)\n",
        "    ent = ''\n",
        "    for t in doc:\n",
        "      \n",
        "      if nostopwds and t.is_stop:\n",
        "        #print(t.text)\n",
        "        continue\n",
        "      if t.like_url:\n",
        "        tokenlist.append('URL')\n",
        "        continue\n",
        "      if not t.is_alpha:\n",
        "        continue      \n",
        "      if lemma:\n",
        "        #print('lemma',text)\n",
        "        tokenlist.append(t.lemma_)\n",
        "      else:\n",
        "        tokenlist.append(t.lower_)\n",
        "    return tokenlist\n",
        "\n",
        "\n",
        "def display_components(model, word_features, top_display=5):\n",
        "    # utility for displaying respresentative words per component for topic models\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(\"Topic %d:\" % (topic_idx))\n",
        "        top_words_idx = topic.argsort()[::-1][:top_display]\n",
        "        top_words = [word_features[i] for i in top_words_idx]\n",
        "        print(\" \".join(top_words))\n",
        "text= \"Lol, th? oh you got &amp friend for the d?g ?.. U.S. I'm at a  buffet... \"\n",
        "tokenize(text,nostopwds=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lol',\n",
              " 'th',\n",
              " 'oh',\n",
              " 'you',\n",
              " 'got',\n",
              " 'amp',\n",
              " 'friend',\n",
              " 'for',\n",
              " 'the',\n",
              " 'i',\n",
              " 'at',\n",
              " 'a',\n",
              " 'buffet']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2lvrBZBWCkc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "7da13444-a7d5-439f-9801-d4ff2acafdfa"
      },
      "source": [
        "tokenlist = [tokenize(str(d)) for d in  df_tweet['text'] ]\n",
        "print(len(tokenlist))\n",
        "cv = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False)\n",
        "vec_cv = cv.fit_transform(tokenlist).toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi7J7L2DXkfE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9ecda384-1dd3-4135-d467-448d835cc66b"
      },
      "source": [
        "print(len(cv.vocabulary_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK_mQbFdWx9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
        "n_components = 20\n",
        "lda = LatentDirichletAllocation(n_components=n_components)\n",
        "lda_vecs = lda.fit_transform(vec_cv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st0aZXnDYWhi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "outputId": "3c85f3f7-ae0f-4b33-9071-29d3bde3038c"
      },
      "source": [
        "\n",
        "print(type(lda.components_),lda.components_.shape)\n",
        "\n",
        "print('Topic List')\n",
        "display_components(lda, cv.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> (20, 12574)\n",
            "Topic List\n",
            "Topic 0:\n",
            "day na gon rain today\n",
            "Topic 1:\n",
            "love URL cool omg hey\n",
            "Topic 2:\n",
            "day bed movie suck tomorrow\n",
            "Topic 3:\n",
            "want m bored like URL\n",
            "Topic 4:\n",
            "work nice like ya going\n",
            "Topic 5:\n",
            "wo outside URL love tonight\n",
            "Topic 6:\n",
            "x thank nt working today\n",
            "Topic 7:\n",
            "sunday haha URL welcome twitter\n",
            "Topic 8:\n",
            "know time great good u\n",
            "Topic 9:\n",
            "URL sorry going day got\n",
            "Topic 10:\n",
            "good morning know lol right\n",
            "Topic 11:\n",
            "sleep looking tired today new\n",
            "Topic 12:\n",
            "u nt s love goodnight\n",
            "Topic 13:\n",
            "days like amp night sweet\n",
            "Topic 14:\n",
            "thanks follow yeah good found\n",
            "Topic 15:\n",
            "got love bad home lol\n",
            "Topic 16:\n",
            "happy birthday miss wait amp\n",
            "Topic 17:\n",
            "sick wish good feel feeling\n",
            "Topic 18:\n",
            "fun u like watching time\n",
            "Topic 19:\n",
            "URL gone game like head\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_puBDxJwwQrj",
        "colab_type": "text"
      },
      "source": [
        "These are very general conversational tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dCD3Y8nsZEj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "47043a10-5d99-44e8-9bf5-67dafcd24ee3"
      },
      "source": [
        "np.argsort(lda_vecs[:, 1])[-5:]\n",
        "lda_vecs.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl4IP7fqu9Bk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "415c581d-702a-45b9-e998-4c313c061028"
      },
      "source": [
        "topiclist = []\n",
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "     x = 'Topic ' + str(topic_idx)\n",
        "     topiclist.append(x)   \n",
        "print(topiclist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Topic 0', 'Topic 1', 'Topic 2', 'Topic 3', 'Topic 4', 'Topic 5', 'Topic 6', 'Topic 7', 'Topic 8', 'Topic 9', 'Topic 10', 'Topic 11', 'Topic 12', 'Topic 13', 'Topic 14', 'Topic 15', 'Topic 16', 'Topic 17', 'Topic 18', 'Topic 19']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14lur7Kbq7Ke",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "f1b43c83-7a4a-485a-a3dc-6f91d4b4ebae"
      },
      "source": [
        "# Top 10 topics\n",
        "tweet_topic = pd.DataFrame(lda_vecs, columns=topiclist)\n",
        "tweet_topic.head()\n",
        "# what's the highest-weighted per movie, look at the top 10\n",
        "tweet_topic.idxmax(axis=1).value_counts()[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Topic 10    705\n",
              "Topic 0     574\n",
              "Topic 3     572\n",
              "Topic 9     560\n",
              "Topic 15    544\n",
              "Topic 11    538\n",
              "Topic 8     515\n",
              "Topic 18    515\n",
              "Topic 2     511\n",
              "Topic 14    504\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmw0eUUyZNJW",
        "colab_type": "text"
      },
      "source": [
        "Topic 10 is most prevalent - good morning know lol right"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvzhsZjwZLhm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}