{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:mainpy3] *",
      "language": "python",
      "name": "conda-env-mainpy3-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "BasicModel.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrGLbbj-KtD1",
        "colab_type": "text"
      },
      "source": [
        "Mukta Mohindra Final project- \n",
        "Sentiment Analysis Twitter text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtZ3Q4t_KtD2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "outputId": "8cc0f336-397c-47a5-c390-c70cf2ee7925"
      },
      "source": [
        "# setup\n",
        "import sys\n",
        "import subprocess\n",
        "import pkg_resources\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "\n",
        "required = {'spacy', 'scikit-learn', 'numpy', \n",
        "            'pandas', 'torch', 'matplotlib', 'wordcloud'}\n",
        " #           'transformers', 'allennlp==0.9.0'}\n",
        "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
        "missing = required - installed\n",
        "\n",
        "if missing:\n",
        "    python = sys.executable\n",
        "    subprocess.check_call([python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pickle\n",
        "#import transformers\n",
        "\n",
        "from spacy.lang.en import English\n",
        "!python -m spacy download en_core_web_md\n",
        "import en_core_web_md\n",
        "en = English()\n",
        "nlp = en_core_web_md.load()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_md==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4MB)\n",
            "\u001b[K     |████████████████████████████████| 96.4MB 1.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (49.2.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.2.5-cp36-none-any.whl size=98051305 sha256=c064ab0e663fbb88735c4ff86bb83d94d39ee077fa884625763d744c3f7c21ca\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xhbq7od8/wheels/df/94/ad/f5cf59224cea6b5686ac4fd1ad19c8a07bc026e13c36502d81\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-8g7NftZrNm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "1fe137e3-7c38-4bcb-83aa-899ddefa88fd"
      },
      "source": [
        "with open('clean_tweets_10k.pkl', 'rb') as f:\n",
        "    df_tweet = pickle.load(f)\n",
        "print(df_tweet.head())\n",
        "df_tweet.info()\n",
        "print('Length',len(df_tweet))\n",
        "##clean out any rows with null values\n",
        "\n",
        "df_tweet.describe()\n",
        "df_tweet['Target'].value_counts()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Target                                               text\n",
            "0       4  @gypsy_sunday :O omg oh yes, I always forget a...\n",
            "1       4  at least i know @sarahtondryk and family will ...\n",
            "2       0      Yesterday it was sunny and today its raining \n",
            "3       4  Going to see Chelsea Art College today.. shoul...\n",
            "4       0  woken up 'early' 3days in a row and im exhaust...\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Target  10000 non-null  int64 \n",
            " 1   text    10000 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 156.4+ KB\n",
            "Length 10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    5014\n",
              "4    4986\n",
              "Name: Target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx8GdYC6m_qe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5853b19-5bdd-4a3a-a477-2d49ae87c79f"
      },
      "source": [
        "\n",
        "#remove punctuation and URLs, and stopwords\n",
        "def tokenize(text, model=nlp, nostopwds=True,  lemma=False):\n",
        "   \n",
        "    tokenlist = []\n",
        "    doc = model(text)\n",
        "    ent = ''\n",
        "    for t in doc:\n",
        "      \n",
        "      if nostopwds and t.is_stop:\n",
        "        #print(t.text)\n",
        "        continue\n",
        "      if t.like_url:\n",
        "        tokenlist.append('URL')\n",
        "        continue\n",
        "      if not t.is_alpha:\n",
        "        continue      \n",
        "      if lemma:\n",
        "        #print('lemma',text)\n",
        "        tokenlist.append(t.lemma_)\n",
        "      else:\n",
        "        tokenlist.append(t.lower_)\n",
        "    return tokenlist\n",
        "text= \"Lol, th? oh @you:all got &amp friend for the d?g ?.. U.S. I'm at a  buffet... Cine there got amore wat... \"\n",
        "print(tokenize(text,nostopwds=False))\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['lol', 'th', 'oh', 'all', 'got', 'amp', 'friend', 'for', 'the', 'i', 'at', 'a', 'buffet', 'cine', 'there', 'got', 'amore', 'wat']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBk7JD6DcTJx",
        "colab_type": "text"
      },
      "source": [
        "#Let us do modeling based on words with log likelihood > 10 based on EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBUba-HgAj6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.utils import shuffle\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2PaDDXmYbRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X = df_tweet['text']\n",
        "y = df_tweet['Target']\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2167b-6gA4G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ddc50bb2-63a6-4a0a-ddcc-6181dcc14d0f"
      },
      "source": [
        "log_words=['want','work','thanks','miss', 'love','new','good','lol']\n",
        "cv = CountVectorizer(tokenizer=tokenize, vocabulary=log_words)\n",
        "vec_cv = cv.fit_transform(df_tweet['text']).toarray()\n",
        "vec_cv.shape\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15_G56eYeJHg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "d3c742e7-36b5-46f0-a1c5-82109935abfb"
      },
      "source": [
        "\n",
        "\n",
        "svc = LinearSVC()\n",
        "X_train, X_test, y_train, y_test = train_test_split(vec_cv, y, \n",
        "                                                        test_size=.3, \n",
        "                                                        random_state=101)\n",
        "svc.fit(X_train,y_train)\n",
        "\n",
        "  "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D5sG4zZIJLi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b7eccc7e-e901-4c4c-d075-d7cfa7cebb82"
      },
      "source": [
        "predict_train = svc.predict(X_train)\n",
        "predict_test = svc.predict(X_test)\n",
        "print('Train Accuracy Score is ',metrics.accuracy_score(y_train, predict_train))\n",
        "print('Test Accuracy Score is ',metrics.accuracy_score(y_test, predict_test))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy Score is  0.5625714285714286\n",
            "Test Accuracy Score is  0.569\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmRYtvf5SrE4",
        "colab_type": "text"
      },
      "source": [
        "#That is very low accuracy, let us model based on the complete tfidf model. Trying 3 models SVC, LogisticRegression, RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcrlHvUchMWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_tweet = shuffle(df_tweet)\n",
        "X = df_tweet['text']\n",
        "y = df_tweet['Target']\n",
        "\n",
        "tf = TfidfVectorizer(tokenizer=tokenize)\n",
        "tf_vec = tf.fit_transform(df_tweet['text'])\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4Ss28q6QR3o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "760b300c-4c8d-460f-e559-bd3b7ce2fda3"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(tf_vec,y, test_size=.3, random_state=53)\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7000, 12558) (3000, 12558)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZek3nukQcXc",
        "colab_type": "text"
      },
      "source": [
        "confusion matrix explanation https://www.geeksforgeeks.org/confusion-matrix-machine-learning/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCRqli53_PIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "def model_predict(X_train,y_train,X_test, y_test, modeltype='SVM'):\n",
        "\n",
        "  if modeltype =='SVM':\n",
        "     model = LinearSVC()\n",
        "  elif modeltype == 'LOGREG':\n",
        "     model = LogisticRegression()\n",
        "  else:\n",
        "     model = RandomForestClassifier()\n",
        "  model.fit(X_train,y_train)\n",
        "  predict_train = model.predict(X_train)\n",
        "  predict_test = model.predict(X_test)\n",
        "  print('Train Accuracy Score ',modeltype, metrics.accuracy_score(y_train, predict_train))\n",
        "  print('Test Accuracy Score ',modeltype, metrics.accuracy_score(y_test, predict_test))\n",
        "  print('confusion matrix\\n',confusion_matrix(y_test, predict_test))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f17AFSV7AlMK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "ea087f00-b0ae-4d18-95d1-7d9f9d8b8af2"
      },
      "source": [
        "#model_predict(tf_vec_train,y_train,tf_vec_test, y_test,'SVM')\n",
        "model_predict(X_train,y_train,X_test, y_test,'SVM')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy Score  SVM 0.9577142857142857\n",
            "Test Accuracy Score  SVM 0.703\n",
            "confusion matrix\n",
            " [[1063  478]\n",
            " [ 413 1046]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G802iFZBmi_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "f2e44710-0a79-403b-fe6d-ab2134883386"
      },
      "source": [
        "model_predict(X_train,y_train,X_test, y_test,'LOGREG')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy Score  LOGREG 0.8737142857142857\n",
            "Test Accuracy Score  LOGREG 0.7266666666666667\n",
            "confusion matrix\n",
            " [[1083  458]\n",
            " [ 362 1097]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJnejMJQriLa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "09f7e3cb-a85e-4f75-a1f0-f5042fc85241"
      },
      "source": [
        "model_predict(X_train,y_train,X_test, y_test,'RANDOM')\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy Score  RANDOM 0.9938571428571429\n",
            "Test Accuracy Score  RANDOM 0.7073333333333334\n",
            "confusion matrix\n",
            " [[1050  491]\n",
            " [ 387 1072]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koHEIsF5Ri-b",
        "colab_type": "text"
      },
      "source": [
        "The train accuracy is high but the test accuracy is very low usually means overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRyAR47MJoT3",
        "colab_type": "text"
      },
      "source": [
        "Let us build a pipeline and save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgLpMbztJfkx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a4a809f-8ace-4b6b-ebd0-40965f1d3cb0"
      },
      "source": [
        "# output simple review-based models for deployment \n",
        "from sklearn.pipeline import Pipeline\n",
        "tf = TfidfVectorizer(lowercase=False, min_df=0.01)\n",
        "vec_tf = tf.fit_transform(df_tweet['text'])\n",
        "df_tweet['Target'].replace(4,1, inplace=True)\n",
        "df_tweet['Target'].value_counts()\n",
        "y = df_tweet['Target'].to_numpy()\n",
        "svc= LinearSVC()\n",
        "svc = svc.fit(vec_tf,y )\n",
        "pipe = Pipeline(steps=[('tfidf', tf), ('svc', svc)])\n",
        "print('test pipe:', pipe.predict([df_tweet.iloc[7]['text']]))\n",
        "pickle.dump(pipe, open('basicmodel_pipe.pkl', 'wb'))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test pipe: [0]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}